{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries générales\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from random import sample\n",
    "from collections import Counter, defaultdict\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.metrics import calinski_harabasz_score, davies_bouldin_score\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "from umap import UMAP\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "data_path = \"../data/\"\n",
    "df = pd.read_pickle(data_path+\"df_2017_avec_auteurs.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1158"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choix du corpus\n",
    "dfh = df[df.rubrique.apply(lambda x : x in set(df.rubrique.head(5)))]\n",
    "dfhi = dfh.reset_index(drop = True)\n",
    "corpus = dfh.question\n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rubriques correspondantes sous forme d'entier\n",
    "l_r = list(dfh.rubrique.unique())\n",
    "dic_r = {l_r[i] : i for i in range(len(l_r))}\n",
    "rubint = dfh.rubrique.apply(lambda x : dic_r[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groupes correspondants sous forme d'entier\n",
    "l_g = list(dfh.groupe_auteur.unique())\n",
    "dic_g = {l_g[i] : i for i in range(len(l_g))}\n",
    "groupint = dfh.groupe_auteur.apply(lambda x : dic_g[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Vecteurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0. TF, TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import for Vectorizer\n",
    "from stop_words import get_stop_words\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "stop_words = get_stop_words('french')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul du TF-IF (pour brut, lsa, nmf ...)\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=stop_words)\n",
    "tfidf = tfidf_vectorizer.fit_transform(corpus)\n",
    "tfidf_vectors = tfidf.toarray()\n",
    "tfidf_feature_names = np.array(tfidf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul du TF (pour LDA)\n",
    "tf_vectorizer = CountVectorizer(stop_words=stop_words)\n",
    "tf = tf_vectorizer.fit_transform(corpus)\n",
    "tf_vectors = tf.toarray()\n",
    "tf_feature_names = np.array(tf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 ACP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import for PCA\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA TF IDF\n",
    "n_components = 10\n",
    "pca = PCA(n_components=n_components, random_state=0)\n",
    "reduced_features_tfidf = pca.fit_transform(tfidf_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA TF\n",
    "random_state = 0\n",
    "dim_pca_tf = 10\n",
    "pca = pca = PCA(n_components=dim_pca_tf, random_state=0)\n",
    "reduced_features_tf = pca.fit_transform(tf_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_lsa = 10 # Pas bon du tout, tenter de voir les meilleures valeurs singulières\n",
    "svd_model = TruncatedSVD(n_components=dim_lsa, algorithm='randomized', n_iter=100, random_state=122)\n",
    "lsa_doc_vectors = svd_model.fit_transform(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsa_word_vectors = svd_model.fit(tfidf).components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10words_lsa = np.array([tfidf_feature_names[(-i).argsort()[:10]] for i in lsa_word_vectors])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_topics_lda = 60\n",
    "lda_doc_model = LatentDirichletAllocation(n_components=n_topics_lda, max_iter=5, learning_method='online', learning_offset=50.,random_state=0).fit(tf.T)\n",
    "lda_doc_vectors = lda_doc_model.components_.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_word_model = LatentDirichletAllocation(n_components=n_topics_lda, max_iter=5, learning_method='online', learning_offset=50.,random_state=0).fit(tfidf)\n",
    "lda_word_vectors = lda_word_model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10words_lda = np.array([tfidf_feature_names[(-i).argsort()[:10]] for i in lda_word_vectors])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_topics_nmf = 100\n",
    "nmf_doc_model = NMF(n_components=n_topics_nmf, random_state=1, alpha=.1, l1_ratio=.5, init='nndsvd').fit(tfidf.T)\n",
    "nmf_doc_vectors = nmf_doc_model.components_.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_word_model = NMF(n_components=n_topics_nmf, random_state=1, alpha=.1, l1_ratio=.5, init='nndsvd').fit(tfidf)\n",
    "nmf_word_vectors = nmf_word_model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10words_nmf = np.array([tfidf_feature_names[(-i).argsort()[:10]] for i in nmf_word_vectors])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.cluster import MiniBatchKMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Exécution du k-means\n",
    "# def go_kmeans(vectors, k = 5):\n",
    "#     random_state = 0\n",
    "#     kmeans = MiniBatchKMeans(n_clusters=k, random_state=random_state)\n",
    "#     kmeans.fit(vectors)\n",
    "#     return kmeans\n",
    "\n",
    "# # Get the clusters of a kmeans\n",
    "# def get_clusters_kmeans(vectors, k=5, kmeans = None):\n",
    "#     if kmeans is None :\n",
    "#         kmeans = go_kmeans(vectors, k)\n",
    "#     return kmeans.predict(vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Hiérarchique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get the clusters of a HAC\n",
    "# def get_clusters_HAC(vectors, n_clusters, linkage, affinity):\n",
    "#     aggc = AgglomerativeClustering(linkage=linkage, affinity=affinity, n_clusters=n_clusters)\n",
    "#     aggc = aggc.fit(vectors)\n",
    "#     return aggc.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 X-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyclustering.cluster.xmeans import xmeans\n",
    "# from pyclustering.cluster.center_initializer import kmeans_plusplus_initializer\n",
    "# from pyclustering.cluster import cluster_visualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get the clusters of a xmeans\n",
    "# def execute_xmeans(vecs,kmin,kmax):\n",
    "#     amount_initial_centers = kmin\n",
    "#     initial_centers = kmeans_plusplus_initializer(vecs, amount_initial_centers).initialize()\n",
    "\n",
    "#     xmeans_instance = xmeans(vecs, initial_centers, kmax)\n",
    "#     xmeans_instance.process()\n",
    "\n",
    "#     groupes = xmeans_instance.get_clusters()\n",
    "#     clusters = pd.Series(\n",
    "#         {j : i for i,m in enumerate(groupes) for j in m}\n",
    "#     ).sort_index().values\n",
    "    \n",
    "#     return clusters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
